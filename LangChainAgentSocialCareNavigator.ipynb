{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eDUt1EB_JzqI",
        "0ZHljlzczAhO"
      ],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopherfan/ChrisFanLLMPractice/blob/main/LangChainAgentSocialCareNavigator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Social Care Navigator Agent Tutorial\n",
        "<img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "\n",
        "Tutorial to create a Social Care Navigator \"Agent\" that can use tools to a) determine the social care needs and b) pull social care programs"
      ],
      "metadata": {
        "id": "7aZWXpbf0Eph"
      },
      "id": "7aZWXpbf0Eph"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Getting started**\n",
        "</div>\n",
        "\n",
        "https://www.pinecone.io/learn/series/langchain/langchain-agents/\n",
        "https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/07-langchain-tools.ipynb"
      ],
      "metadata": {
        "id": "OQ_SlL0K1Cw6"
      },
      "id": "OQ_SlL0K1Cw6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize LLM"
      ],
      "metadata": {
        "id": "rg_UQVkMrTES"
      },
      "id": "rg_UQVkMrTES"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain"
      ],
      "metadata": {
        "id": "oUfKG_uS4dDe"
      },
      "id": "oUfKG_uS4dDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-google-vertexai"
      ],
      "metadata": {
        "id": "Q_-itio4cJxm"
      },
      "id": "Q_-itio4cJxm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform --upgrade"
      ],
      "metadata": {
        "id": "goeqZ0VI4mQB"
      },
      "id": "goeqZ0VI4mQB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "XiQvK1NKSMxB"
      },
      "id": "XiQvK1NKSMxB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import auth\n",
        "\n",
        "#PROJECT_ID = \"ai-dev-400222\"  # @param {type:\"string\"}\n",
        "\n",
        "#auth.authenticate_user(project_id=PROJECT_ID)\n",
        "\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "ByrsUK4BR7Tf"
      },
      "id": "ByrsUK4BR7Tf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain.llms import VertexAI\n",
        "from langchain_google_vertexai import VertexAI\n",
        "#llm = VertexAI(model_name = 'text-bison@001')\n",
        "llm = VertexAI(model_name=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "bOXzLGry0Id-"
      },
      "id": "bOXzLGry0Id-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"What does the company Aunt Bertha do as a company?\"))"
      ],
      "metadata": {
        "id": "zNC0kIM14u5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465bd556-8242-4782-9caa-ade36f360c28"
      },
      "id": "zNC0kIM14u5x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aunt Bertha is a nonprofit organization that provides a comprehensive directory of social service programs and resources. The organization's mission is to connect people in need with the services that can help them.\n",
            "\n",
            "Aunt Bertha's directory includes information on more than 100,000 programs and resources, covering a wide range of topics, including:\n",
            "\n",
            "* Affordable housing\n",
            "* Food assistance\n",
            "* Healthcare\n",
            "* Job training\n",
            "* Mental health services\n",
            "* Substance abuse treatment\n",
            "* Childcare\n",
            "* Eldercare\n",
            "* Legal aid\n",
            "* Financial assistance\n",
            "* Veterans services\n",
            "\n",
            "Aunt Bertha's directory is available online and through a mobile app. The organization also provides a free hotline, where people can speak with a trained specialist who can help them find the resources they need.\n",
            "\n",
            "Aunt Bertha is a valuable resource for people who are struggling to make ends meet. The organization's directory can help people find the services they need to get back on their feet and improve their lives.\n",
            "\n",
            "Here are some specific examples of how Aunt Bertha has helped people:\n",
            "\n",
            "* A single mother with two young children was struggling to pay her rent and buy groceries. She was able to find a list of local food banks and housing assistance programs on Aunt Bertha's website.\n",
            "* A man who was struggling with addiction was able to find a list of local treatment programs on Aunt Bertha's website. He was able to get the help he needed to overcome his addiction and start a new life.\n",
            "* A senior citizen who was struggling to pay her medical bills was able to find a list of local programs that provide financial assistance to seniors on Aunt Bertha's website. She was able to get the help she needed to pay her medical bills and stay in her home.\n",
            "\n",
            "Aunt Bertha is a valuable resource for people who are struggling to make ends meet. The organization's directory can help people find the services they need to get back on their feet and improve their lives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEqfoSz7RY1w",
        "outputId": "b31d71d1-38b2-4ae4-d4be-fb43238ecf84"
      },
      "id": "tEqfoSz7RY1w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.0.86)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "W0vSh2UAR794"
      },
      "id": "W0vSh2UAR794",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__3f9028b687f6414a81c9c7156b4ecde5\"  # Update to your API key\n",
        "\n"
      ],
      "metadata": {
        "id": "y7_82G7-RfOL"
      },
      "id": "y7_82G7-RfOL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()"
      ],
      "metadata": {
        "id": "ldNTAM8rSZxM"
      },
      "id": "ldNTAM8rSZxM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SURwRMiyxQE1"
      },
      "id": "SURwRMiyxQE1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tutorial for Creating Custom Agent Tools\n",
        "\n",
        "URL [link text](https://www.pinecone.io/learn/series/langchain/langchain-agents/)"
      ],
      "metadata": {
        "id": "ZwzsvhA500nL"
      },
      "id": "ZwzsvhA500nL"
    },
    {
      "cell_type": "code",
      "source": [
        "## Create LLM Math Tool\n",
        "from langchain.chains import LLMMathChain\n",
        "from langchain.agents import Tool"
      ],
      "metadata": {
        "id": "KIDn-KngJF0R"
      },
      "id": "KIDn-KngJF0R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create LLM Math Tool\n",
        "from langchain.chains import LLMMathChain\n",
        "from langchain.agents import Tool\n",
        "\n",
        "llm_math = LLMMathChain(llm=llm)\n",
        "\n",
        "# initialize the math tool\n",
        "math_tool = Tool(\n",
        "    name='Calculator',\n",
        "    func=llm_math.run,\n",
        "    description='Useful for when you need to answer questions about math.'\n",
        ")\n",
        "# when giving tools to LLM, we must pass as list of tools\n",
        "tools = [math_tool]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaa3eNUy40Hl",
        "outputId": "6f354d91-6e2f-4517-b5e5-865e256c87cf"
      },
      "id": "aaa3eNUy40Hl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py:57: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## List tools in the toosl list\n",
        "tools[0].name, tools[0].description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTiXustA6gw-",
        "outputId": "4fd2b0e4-c87b-4679-e58d-df6b353dc2ad"
      },
      "id": "sTiXustA6gw-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Calculator', 'Useful for when you need to answer questions about math.')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the Agent and instantiate the LLM\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "v7E4JI_w6quI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e5bbce-a8c9-4240-fd5a-caea1446313e"
      },
      "id": "v7E4JI_w6quI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test using the Math Tool from simple zero shot prompt\n",
        "\n",
        "\n",
        "llm_answer = zero_shot_agent.invoke(\"what is (4.5*2.1)^2.2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NTTyG9x62P1",
        "outputId": "908d0d3d-06ff-4e32-aa4d-fe320be00164"
      },
      "id": "2NTTyG9x62P1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use my calculator to evaluate this expression\n",
            "Action: Calculator\n",
            "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 139.94261298333066\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su-u4gOL7DGh",
        "outputId": "5f0ebfb1-d9a6-40be-ce16-515b95250682"
      },
      "id": "Su-u4gOL7DGh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Simple tool that can call general LLM\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"{query}\"\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# initialize the LLM tool\n",
        "llm_tool = Tool(\n",
        "    name='Language Model',\n",
        "    func=llm_chain.run,\n",
        "    description='use this tool for general purpose queries and logic'\n",
        ")\n",
        "\n",
        "tools.append(llm_tool)"
      ],
      "metadata": {
        "id": "dBSfMz2e85k4"
      },
      "id": "dBSfMz2e85k4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHNhcwudJn1I",
        "outputId": "271ba679-6580-40b3-8b18-dd762ca9708f"
      },
      "id": "RHNhcwudJn1I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=VertexAI(model_name='gemini-pro', client=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a95a12af8b0>, client_preview=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a9490c73f10>)), llm=VertexAI(model_name='gemini-pro', client=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a95a12af8b0>, client_preview=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a9490c73f10>))>), Tool(name='Language Model', description='use this tool for general purpose queries and logic', func=<bound method Chain.run of LLMChain(prompt=PromptTemplate(input_variables=['query'], template='{query}'), llm=VertexAI(model_name='gemini-pro', client=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a95a12af8b0>, client_preview=<vertexai.preview.generative_models._PreviewGenerativeModel object at 0x7a9490c73f10>))>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reinitialize the agent now with the multiple tools [Calculator, general LLM]\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "oIp-TKim9SUu"
      },
      "id": "oIp-TKim9SUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Debug\n",
        "llm_answer = zero_shot_agent(\"Describe the company findhelp.\")"
      ],
      "metadata": {
        "id": "P0F_N1Cu8_Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0430be-8839-47eb-f029-bf1f4a78718d"
      },
      "id": "P0F_N1Cu8_Hq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mfindhelp is an online platform that connects people with mental health and substance use disorders with behavioral health providers and resources.\n",
            "Action: Language Model\n",
            "Action Input: What is findhelp?\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mFindhelp is an online resource that allows users to search for local social services in the United States. It is a comprehensive directory of more than 200,000 programs and services, including everything from food banks and housing assistance to addiction treatment and job training.\n",
            "\n",
            "Findhelp is a free and anonymous service. Users can search for services by zip code, city, state, or type of service. They can also browse through a list of services by category.\n",
            "\n",
            "Findhelp is a great resource for anyone who is looking for help with a particular issue or who is simply trying to learn more about the social services that are available in their community.\n",
            "\n",
            "Here are some of the benefits of using Findhelp:\n",
            "\n",
            "* It is a comprehensive directory of social services, with listings for over 200,000 programs and services.\n",
            "* It is free and anonymous.\n",
            "* It is easy to use. Users can search for services by zip code, city, state, or type of service.\n",
            "* It is a great way to learn about the social services that are available in your community.\n",
            "\n",
            "If you are looking for help with a particular issue or if you are simply trying to learn more about the social services that are available in your community, Findhelp is a great resource.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Findhelp is an online platform that connects people with mental health and substance use disorders with behavioral health providers and resources. It is a comprehensive directory of social services, with listings for over 200,000 programs and services, including food banks and housing assistance to addiction treatment and job training.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlr4nFLrKDLv",
        "outputId": "85e6697f-dc8b-467f-9b22-4de68432732c"
      },
      "id": "dlr4nFLrKDLv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Describe the company findhelp.', 'output': 'Findhelp is an online platform that connects people with mental health and substance use disorders with behavioral health providers and resources. It is a comprehensive directory of social services, with listings for over 200,000 programs and services, including food banks and housing assistance to addiction treatment and job training.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Debug asking the same agent a complicated math question\n",
        "llm_answer = zero_shot_agent(\"What is the (square root of 5) ^ 7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmMUdDAQKa6w",
        "outputId": "9252a7c5-7ae8-41f2-a5a2-3107b80edb4f"
      },
      "id": "RmMUdDAQKa6w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI can use my calculator to calculate this\n",
            "Action: Calculator\n",
            "Action Input: (sqrt(5)) ^ 7\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 1.0126531154397722\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 1.0126531154397722\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evyiyPQ-Kg5e",
        "outputId": "ce97ba1c-0311-4dea-c2c2-b93e9f26eee1"
      },
      "id": "evyiyPQ-Kg5e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'What is the (square root of 5) ^ 7', 'output': '1.0126531154397722'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from math import sqrt, cos, sin\n",
        "from typing import Union"
      ],
      "metadata": {
        "id": "ofD0UrkwQSxZ"
      },
      "id": "ofD0UrkwQSxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the explicit declaration of class to define the tool\n",
        "\n",
        "from langchain.tools import StructuredTool\n",
        "\n",
        "desc = (\n",
        "    \"use this tool when you need to calculate the length of a hypotenuse\"\n",
        "    \"given one or two sides of a triangle and/or an angle (in degrees). \"\n",
        "    \"To use the tool, you must provide at least two of the following parameters \"\n",
        "    \"['adjacent_side', 'opposite_side', 'angle'].\"\n",
        ")\n",
        "\n",
        "class PythagorasTool(StructuredTool):\n",
        "    name = \"Hypotenuse calculator\"\n",
        "    description = desc\n",
        "\n",
        "    def _run(\n",
        "        self,\n",
        "        adjacent_side: Optional[Union[int, float]] = None,\n",
        "        opposite_side: Optional[Union[int, float]] = None,\n",
        "        angle: Optional[Union[int, float]] = None\n",
        "    ):\n",
        "        # check for the values we have been given\n",
        "        if adjacent_side and opposite_side:\n",
        "            return sqrt(float(adjacent_side)**2 + float(opposite_side)**2)\n",
        "        elif adjacent_side and angle:\n",
        "            return adjacent_side / cos(float(angle))\n",
        "        elif opposite_side and angle:\n",
        "            return opposite_side / sin(float(angle))\n",
        "        else:\n",
        "            return \"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`.\"\n",
        "\n",
        "    def _arun(self, query: str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "tools = [PythagorasTool]"
      ],
      "metadata": {
        "id": "2hWrFTE1QObB"
      },
      "id": "2hWrFTE1QObB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install google-search-results"
      ],
      "metadata": {
        "id": "Nein0YzCPDXl"
      },
      "id": "Nein0YzCPDXl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple Agent that calls external Search tool https://www.pinecone.io/learn/series/langchain/langchain-agents/\n",
        "\n",
        "from langchain import SerpAPIWrapper\n",
        "\n",
        "# initialize the search chain\n",
        "search = SerpAPIWrapper(serpapi_api_key='--enter key')\n",
        "\n",
        "# create a search tool\n",
        "serAPI_tool =  Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.run,\n",
        "        description='google search'\n",
        "    )\n",
        "\n",
        "\n",
        "tools = [serAPI_tool]\n",
        "\n",
        "# initialize the search enabled agent\n",
        "self_ask_with_search = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"self-ask-with-search\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "n0gQOdcxnZ8s"
      },
      "id": "n0gQOdcxnZ8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer = self_ask_with_search(\n",
        "    \"Who won the game between the Chiefs and the Ravens?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpN1rIIcPMPB",
        "outputId": "a9e20e4d-909f-435a-993d-022c31928e3c"
      },
      "id": "EpN1rIIcPMPB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes.\n",
            "Follow up: When was the game between the Chiefs and the Ravens?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m{'title': '2023 AFC Championship Game', 'game_spotlight': {'league': 'NFL', 'stadium': 'M&T Bank Stadium', 'date': 'Sun, Jan 28', 'stage': 'Final', 'video_highlights': {'link': 'https://www.youtube.com/watch?v=jb_lnAvZSa4&feature=onebox', 'thumbnail': 'https://ssl.gstatic.com/onebox/media/sports/videos/vita/yOwWrIhpnxqmhWhC_192x108.jpg', 'duration': '15:10'}, 'teams': [{'name': 'Kansas City Chiefs', 'thumbnail': 'https://serpapi.com/searches/65c15dc8ada54b1cfcb95b41/images/93e6684cc46470436efd33bd767df21a08e709a6e25369ed8ebb07bc95257faa4e320a97e4b464a00580c09b57c997be.png', 'team_stats': {'wins': 14, 'losses': 6}, 'score': '17'}, {'name': 'Baltimore Ravens', 'thumbnail': 'https://serpapi.com/searches/65c15dc8ada54b1cfcb95b41/images/93e6684cc46470436efd33bd767df21a08e709a6e25369ed8ebb07bc95257faa87bf9161a69843accbdd5bac18042555.png', 'team_stats': {'wins': 14, 'losses': 5}, 'score': '10'}]}}\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAre follow up questions needed here: Yes.\n",
            "Follow up: What is the score of the game?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m['Fast, updating NFL football game scores and stats as games are in progress are provided by CBSSports.com.', 'Live scores for every 2023 NFL season game on ESPN. Includes box scores, video highlights, play breakdowns and updated odds.', 'The official scoreboard of the NFL including live scoring and real-time highlights.', 'Upcoming · San Francisco. 49ers. 12-5 · Kansas City. Chiefs. 11-6.', 'Live NFL football scores on SI.com.', 'Stay updated with live NFL game scores, updated odds, and team leaders for all Week 23 matchups in the 2023 NFL season.', 'Live scores for every 2024 NFL game this season on FOX Sports. Real time NFL scores include box scores, updated odds, video highlights and stats.', 'National Football Association - Scores, Stats, News, Rumors, Videos, Standings, Teams.', 'Fast, updating NFL football game scores and stats as games are in progress are provided by CBSSports.com.', \"Visit FOXSports.com for today's top sports scores and games. Explore real-time game scores across MLB, NBA, NFL, Soccer, NHL and more.\"]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAre follow up questions needed here: Yes.\n",
            "Follow up: Who won the game?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m['Live scores for every 2023 NFL season game on ESPN. Includes box scores, video highlights, play breakdowns and updated odds.', 'The official scoreboard of the NFL including live scoring and real-time highlights.', 'Fast, updating NFL football game scores and stats as games are in progress are provided by CBSSports.com.', 'Get the latest news and information for the Miami Heat. 2023 season schedule, scores, stats, and highlights. Find out the latest on your favorite NBA teams ...', 'Watch NBA Games - Follow the game, scores and stats for NBA matchups.', 'Live scores for every 2023-24 NBA season game on ESPN. Includes box scores, video highlights, play breakdowns and updated odds.', \"Visit FOXSports.com for today's top sports scores and games. Explore real-time game scores across MLB, NBA, NFL, Soccer, NHL and more.\", 'NEW YORK (AP) — LeBron James scored 24 points and the Los Angeles Lakers pulled away down the stretch to beat New York 113-105 Saturday night, ...', 'San Francisco. 49ers. 12-5 · Kansas City. Chiefs. 11-6.', 'Stay updated with live NBA game scores, updated odds, and team leaders for all matchups in the 2023-24 NBA season.']\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: Kansas City Chiefs\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aWdEXygYMZe",
        "outputId": "10a0ca13-4d1c-4b60-991e-66f0dda3e959"
      },
      "id": "3aWdEXygYMZe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Who won the game between the Chiefs and the Ravens?', 'output': 'Invalid or incomplete response'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Can we combine 3 tools to be used by the same agent? 1: Math 2: General LLM 3: Search?\n",
        "\n",
        "#Clear the tools array\n",
        "tools = []\n",
        "\n",
        "# We have previously created each of the tools 1: math_tool() 2: llm_tool  3: serAPI_tool\n",
        "\n",
        "tools.append(math_tool)\n",
        "tools.append(llm_tool)\n",
        "tools.append(serAPI_tool)\n",
        "\n"
      ],
      "metadata": {
        "id": "6Ch6HbS_PjeN"
      },
      "id": "6Ch6HbS_PjeN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tool in tools:\n",
        "  print (f\"Name: {tool.name} Description: {tool.description}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8hAm9fFQsZ0",
        "outputId": "acc363d9-8b6a-42ab-c9d4-362383314dbd"
      },
      "id": "t8hAm9fFQsZ0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Calculator Description: Useful for when you need to answer questions about math.\n",
            "Name: Language Model Description: use this tool for general purpose queries and logic\n",
            "Name: Intermediate Answer Description: google search\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can we use the agent with the 3 tools?\n",
        "\n",
        "# initialize the search enabled agent\n",
        "self_ask_with_search = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "i9ipH-XLSQ_n"
      },
      "id": "i9ipH-XLSQ_n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_ask_with_search(\"Who won the game between the Chiefs and the Ravens?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j48iOaaXSUYC",
        "outputId": "14e8b239-4916-40d7-908f-eb9f6b19bbbd"
      },
      "id": "j48iOaaXSUYC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI do not have access to real-time information, so I cannot answer this question.\n",
            "Final Answer: I cannot answer this question.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Who won the game between the Chiefs and the Ravens?',\n",
              " 'output': 'I cannot answer this question.'}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Social Care Navigator \"Aunt Bertha\" Prompt Generation with Conversational Memory"
      ],
      "metadata": {
        "id": "OFHBVpwD1DZ6"
      },
      "id": "OFHBVpwD1DZ6"
    },
    {
      "cell_type": "code",
      "source": [
        "### Import Langchain Templates\n",
        "\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import HumanMessagePromptTemplate\n",
        "from langchain.schema.messages import SystemMessage\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ],
      "metadata": {
        "id": "Lg1EKfTv-Sxe"
      },
      "id": "Lg1EKfTv-Sxe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "#importlib.reload (AgentAuntBerthaPrompt)"
      ],
      "metadata": {
        "id": "9snfxGpCXAYe"
      },
      "id": "9snfxGpCXAYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import AgentAuntBerthaPrompt\n",
        "#from AgentAuntBerthaPrompt import template\n",
        "from AgentAuntBerthaPrompt import system_template\n",
        "from AgentAuntBerthaPrompt import needs_evaluator"
      ],
      "metadata": {
        "id": "G1OvBXo9AnXU"
      },
      "id": "G1OvBXo9AnXU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set System Message from Prompt Above\n",
        "#system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# Try out a more simple text completion prompt\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(needs_evaluator)\n",
        "\n",
        "# Set the Human input as a placeholder variable to enter\n",
        "human_template=\"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n"
      ],
      "metadata": {
        "id": "JN2B4Z_6bwjD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JN2B4Z_6bwjD"
    },
    {
      "cell_type": "code",
      "source": [
        "system_message_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_QYRqXDYJ0J",
        "outputId": "8597ddd1-e720-4d95-c3e5-4bfa505fa546"
      },
      "id": "8_QYRqXDYJ0J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\n\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\n\\nThere are 4 unique data-points that are required \\n\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\n\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\n\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\n\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\n\\n\\nIf there is missing information, you will reply back with what information is missing only. \\n\\n\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\n\\nThese are examples of valid sentences\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\n\\n\\n'))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a single chat prompt\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [system_message_prompt, human_message_prompt]\n",
        "    )\n",
        "\n",
        "# See the full System and Human Prompt with an intial input\n",
        "chat_prompt.format_messages(text=\"I am looking for food\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vI_DM5PecIKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038aa63d-79a0-402c-c718-29a858c0455c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\n\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\n\\nThere are 4 unique data-points that are required \\n\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\n\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\n\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\n\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\n\\n\\nIf there is missing information, you will reply back with what information is missing only. \\n\\n\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\n\\nThese are examples of valid sentences\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\n\\n\\n'),\n",
              " HumanMessage(content='I am looking for food')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "id": "vI_DM5PecIKl"
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_VertexLLM = ChatVertexAI()\n",
        "\n",
        "#Instantiate the LLM with the Gemini Model\n",
        "chat_VertexLLM = VertexAI(model_name=\"gemini-pro\",temperature=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "fimfAmUiCSrP"
      },
      "id": "fimfAmUiCSrP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_VertexLLM(chat_prompt.format_messages(text=\"I am looking for place to stay for the night\"))\n",
        "\n",
        "#New way to invoke the Model via Gemini (add the .invoke)\n",
        "\n",
        "chat_VertexLLM.invoke(chat_prompt.format_messages(text=\"I am want to find food pantries near me in San Francisco. I can go on Saturday Mornings.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sBBEZ5IrCYM1",
        "outputId": "84466212-701e-4be5-c2f0-cc398ede6d3c"
      },
      "id": "sBBEZ5IrCYM1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Missing information: Distance and Day_times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Chain from Prompt Template and LLM\n",
        "\n",
        "chain = chat_prompt | chat_VertexLLM"
      ],
      "metadata": {
        "id": "vv8jkrMk3QAk"
      },
      "id": "vv8jkrMk3QAk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Invoke LLM with user prompt\n",
        "user_prompt = \"I am looking for day care.\"\n",
        "\n",
        "print(chain.invoke({\"text\":user_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQugRhKk3f2J",
        "outputId": "3654a326-8fc2-4db2-db32-9aceacfcac4b"
      },
      "id": "pQugRhKk3f2J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: Location, Distance, Day_times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Long-Term Memory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "\n",
        "conversation_buf = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "VGWRwjEg129_"
      },
      "id": "VGWRwjEg129_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = chat_prompt.format_messages(text=\"I am looking for food\")\n",
        "\n",
        "conversation_buf.invoke(user_prompt)"
      ],
      "metadata": {
        "id": "chXhvD6G4d3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2816aa2d-be61-4106-b09e-1b9f4966d1c0"
      },
      "id": "chXhvD6G4d3v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': [SystemMessage(content='\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\n\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\n\\nThere are 4 unique data-points that are required \\n\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\n\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\n\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\n\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\n\\n\\nIf there is missing information, you will reply back with what information is missing only. \\n\\n\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\n\\nThese are examples of valid sentences\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\n\\n\\n'),\n",
              "  HumanMessage(content='I am looking for food')],\n",
              " 'history': '',\n",
              " 'response': \"Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"Oakland\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B43Q8vD8ekGo",
        "outputId": "04e87ade-35bb-4682-915c-cd188ab467bf"
      },
      "id": "B43Q8vD8ekGo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Oakland',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': \"Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"94530\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpZlGUm1er-f",
        "outputId": "48411773-80f0-47f3-e982-2c91612b1b72"
      },
      "id": "rpZlGUm1er-f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '94530',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Oakland\\nAI: Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': \"Thank you for providing your zip code. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"Yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PICspI-lexB3",
        "outputId": "9eddecba-e439-4761-9e14-d8d7d9ed7166"
      },
      "id": "PICspI-lexB3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Yes',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Oakland\\nAI: Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: 94530\\nAI: Thank you for providing your zip code. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': \"Thank you for confirming your location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"Saturday mornings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1Kop409ez_U",
        "outputId": "6febb14f-3660-4939-8a6c-dce8cc2f4ae5"
      },
      "id": "o1Kop409ez_U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Saturday mornings',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Oakland\\nAI: Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: 94530\\nAI: Thank you for providing your zip code. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Yes\\nAI: Thank you for confirming your location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': \"Thank you for providing your preferred day and time. To ensure accuracy, I need one final piece of information from you:\\n\\n**Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance on Saturday mornings. This will help me narrow down the search results to locations that are convenient for you.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"10 miles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6qI07DQe5IP",
        "outputId": "8b61e745-530e-401a-d9ec-1a3763ee8aec"
      },
      "id": "B6qI07DQe5IP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '10 miles',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Oakland\\nAI: Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: 94530\\nAI: Thank you for providing your zip code. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Yes\\nAI: Thank you for confirming your location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Saturday mornings\\nAI: Thank you for providing your preferred day and time. To ensure accuracy, I need one final piece of information from you:\\n\\n**Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance on Saturday mornings. This will help me narrow down the search results to locations that are convenient for you.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': \"Perfect! I have all the information I need to conduct a comprehensive program search for food assistance near you. Here's a summary of your preferences:\\n\\n**Location:** Oakland, CA 94530\\n**Distance:** Up to 10 miles\\n**Day and Time:** Saturday mornings\\n\\nBased on these preferences, I will search for food assistance programs that are located within a 10-mile radius of 94530, are open on Saturday mornings, and align with your needs.\\n\\nPlease confirm that this information is correct before I proceed with the search. Once you confirm, I'll generate a URL with a term and zip code to find the most relevant and suitable food assistance programs near you.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf.invoke(\"Yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPnkcGoTe8MC",
        "outputId": "b4330ecd-95ba-4336-d1fd-4621fdd218be"
      },
      "id": "aPnkcGoTe8MC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Yes',\n",
              " 'history': \"Human: [{'content': '\\\\nYour name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\\\\n\\\\nYour goal is to determine whether there is sufficient information provided from the user to conduct a Program Search. \\\\n\\\\nThere are 4 unique data-points that are required \\\\n\\\\n[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\\\\n\\\\n2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code. It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\\\\n\\\\n3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\\\\n\\\\n4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”. If the user has no preference they can state that they prefer any time of the week. \\\\n\\\\n\\\\nIf there is missing information, you will reply back with what information is missing only. \\\\n\\\\n\\\\nOnly if all 4 data points are present, you will create a 1 sentence description like the following:\\\\n“Ask the user to confirm the statement. Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\\\\n\\\\nThese are examples of valid sentences\\\\n“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\\\\n“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\\\\n\\\\n\\\\n', 'additional_kwargs': {}, 'type': 'system'}, {'content': 'I am looking for food', 'additional_kwargs': {}, 'type': 'human', 'example': False}]\\nAI: Thank you for your inquiry. I can certainly help you with that. However, I will need you to provide me with additional details to conduct a comprehensive program search for food services. Specifically, I will need the following information:\\n\\n**1. Location:** Please tell me the city and state where you would like to receive food assistance. Alternatively, you can provide me with your zip code.\\n\\n**2. Distance:** Let me know the maximum distance you're willing to travel to get food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**3. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please let me know. This way, I can find programs that align with your schedule.\\n\\nOnce I have all these details, I'll be able to create a 1-sentence description confirming your preferences and then generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Oakland\\nAI: Thank you for providing the location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from Oakland to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: 94530\\nAI: Thank you for providing your zip code. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Yes\\nAI: Thank you for confirming your location. To ensure accuracy, I'll need a bit more information from you:\\n\\n**1. Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance. This will help me narrow down the search results to locations that are convenient for you.\\n\\n**2. Day and Times:** If you have any preferred days and times during the week when you would like to receive food assistance, please share those with me. This way, I can find programs that align with your schedule.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: Saturday mornings\\nAI: Thank you for providing your preferred day and time. To ensure accuracy, I need one final piece of information from you:\\n\\n**Distance:** Please let me know the maximum distance you are willing to travel from 94530 to receive food assistance on Saturday mornings. This will help me narrow down the search results to locations that are convenient for you.\\n\\nOnce I have this information, I'll be able to provide you with a 1-sentence description confirming your preferences and generate a URL with a term and zip code. This will allow me to find the most relevant and suitable food assistance programs near you.\\nHuman: 10 miles\\nAI: Perfect! I have all the information I need to conduct a comprehensive program search for food assistance near you. Here's a summary of your preferences:\\n\\n**Location:** Oakland, CA 94530\\n**Distance:** Up to 10 miles\\n**Day and Time:** Saturday mornings\\n\\nBased on these preferences, I will search for food assistance programs that are located within a 10-mile radius of 94530, are open on Saturday mornings, and align with your needs.\\n\\nPlease confirm that this information is correct before I proceed with the search. Once you confirm, I'll generate a URL with a term and zip code to find the most relevant and suitable food assistance programs near you.\",\n",
              " 'response': 'Fantastic! I\\'m glad that the information I have gathered is accurate. Here\\'s a 1-sentence description confirming your preferences:\\n\\n**I can help you find food assistance programs near Oakland, CA 94530, within a 10-mile radius, open on Saturday mornings.**\\n\\nPlease note that this is just a summary; the actual URL I generate may vary slightly.\\n\\nGenerating URL...\\n\\nHere\\'s the URL:\\n\\n**https://findhelp.org/food-pantries?lat=37.7749295&lng=-122.2197902&zip=94530&distance=10&day=Saturday&time=morning&nocache=true**\\n\\nThis URL includes the search term \"food pantries,\" your location (Oakland, CA 94530), the maximum distance (10 miles), the preferred day (Saturday), and the preferred time (morning). By clicking on this link, you will be directed to a list of food assistance programs that meet your specific criteria.\\n\\nPlease let me know if you have any other questions or if there\\'s anything else I can assist you with.'}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Simple Tool as Call Back Function Dummy Social Care Program\n",
        "\n",
        "\n",
        "Simply outputs a set string for a Menu"
      ],
      "metadata": {
        "id": "CRyzrPppzSCN"
      },
      "id": "CRyzrPppzSCN"
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "importlib.reload(AgentAuntBerthaPrompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7PZ2ZuTLatn",
        "outputId": "1aa51833-7a9d-4806-9a4d-fb2351038268"
      },
      "id": "q7PZ2ZuTLatn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'AgentAuntBerthaPrompt' from '/content/AgentAuntBerthaPrompt.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a simple call back function\n",
        "\n",
        "from langchain.tools import BaseTool\n",
        "\n",
        "\n",
        "class ProgramRecommendation(BaseTool):\n",
        "    name = \"Program Recommendation\"\n",
        "\n",
        "    description = \"Use this tool when to find a social care program when have the criteria [a:need description][b:location][c:distance][d:time]. All criteria must be passed.\"\n",
        "\n",
        "    def _run(\n",
        "        self,\n",
        "        need_description: str= None,\n",
        "        distance: str= None,\n",
        "        location: str= None,\n",
        "        time: str= None,\n",
        "        ):\n",
        "      return f\"There is a St. Vincent de Paul Society Food Pantry run by the  St. Jerome Catholic Church that is located at 308 Carmel Avenue, El Cerrito, CA 94530 that is open Wednesday: 10:30 AM - 11:30 AM PST\"\n",
        "\n",
        "    def _arun (self, dummy:str):\n",
        "      return NotImplementedError (\"Tool does not support async\")\n",
        "\n",
        "## Add the dummy tool to the tools array\n",
        "tools = []\n",
        "tools.append(ProgramRecommendation())\n"
      ],
      "metadata": {
        "id": "IzzvyzfAEyvO"
      },
      "id": "IzzvyzfAEyvO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Simple Conversational Chat Agent\n",
        "\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "\n",
        "# initialize conversational memory\n",
        "conversational_memory = ConversationBufferWindowMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "6VzlOv6HqpS0"
      },
      "id": "6VzlOv6HqpS0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Tool using Bertha Prompt"
      ],
      "metadata": {
        "id": "eDUt1EB_JzqI"
      },
      "id": "eDUt1EB_JzqI"
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "#importlib.reload(AgentAuntBerthaPrompt)\n",
        "\n",
        "from AgentAuntBerthaPrompt import needs_example, prompt_detect_needs\n"
      ],
      "metadata": {
        "id": "3cr6vlrZLxuS"
      },
      "id": "3cr6vlrZLxuS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    FewShotChatMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "import importlib\n",
        "from langchain.schema.messages import SystemMessage"
      ],
      "metadata": {
        "id": "bKYuHxcaOMGL"
      },
      "id": "bKYuHxcaOMGL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool, StructuredTool, tool"
      ],
      "metadata": {
        "id": "zqheaC03obe5"
      },
      "id": "zqheaC03obe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a prompt template used to format each individual example.\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{UserNeed}\"),\n",
        "        (\"ai\", \"{Evaluation}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=needs_example,\n",
        ")"
      ],
      "metadata": {
        "id": "a2KHRtrKNmoy"
      },
      "id": "a2KHRtrKNmoy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set System Prompt imported from a file\n",
        "\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(prompt_detect_needs)\n",
        "\n",
        "# Set the Human input as a placeholder variable to enter\n",
        "human_template=\"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "kZM7Qb9WObdO"
      },
      "id": "kZM7Qb9WObdO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [system_message_prompt,few_shot_prompt, human_message_prompt]\n",
        "    )"
      ],
      "metadata": {
        "id": "IKQOcGLoOk0O"
      },
      "id": "IKQOcGLoOk0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_VertexLLM = ChatVertexAI()\n",
        "#Set to using Gemini\n",
        "chat_VertexLLM = VertexAI(model_name=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "KZzSsRppOvtV"
      },
      "id": "KZzSsRppOvtV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | chat_VertexLLM"
      ],
      "metadata": {
        "id": "pg8vwtqcOxaZ"
      },
      "id": "pg8vwtqcOxaZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Invoke LLM with user prompt\n",
        "user_prompt = \"I am living in my car near Berkeley and need help. \"\n",
        "\n",
        "print(chain.invoke({\"text\":user_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN--V77oO0H4",
        "outputId": "89a45dcd-9149-4336-bb9f-94d1b365b9d8"
      },
      "id": "RN--V77oO0H4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can see that you might be looking for homeless assistance near Berkeley. So that I can help you, please provide the missing information:\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "\n",
        "class GetUserNeeds(BaseTool):\n",
        "    name = \"Get User Needs\"\n",
        "\n",
        "    description = \"Use this tool when a user has expressed a need so that you can gather the users's a) need b) location and zip code c) times of the week and d) distance to search\"\n",
        "\n",
        "    def _run(self, user_prompt: str):\n",
        "      return chain.invoke({\"text\":user_prompt})\n",
        "    def _arun (self, dummy:str):\n",
        "      return NotImplementedError (\"Tool does not support async\")\n",
        "\n",
        "## Add the dummy tool to the tools array\n",
        "tools.append(GetUserNeeds())\n",
        "\n"
      ],
      "metadata": {
        "id": "dHQa1uDyJ15G"
      },
      "id": "dHQa1uDyJ15G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Create Simple tool that can call general LLM\n",
        "\n",
        "# from langchain.chains import LLMChain\n",
        "# from langchain.agents import Tool\n",
        "\n",
        "\n",
        "# llm_chain = LLMChain(llm=chat_VertexLLM, prompt=chat_prompt)\n",
        "\n",
        "# # initialize the LLM tool\n",
        "# getUserNeeds = Tool(\n",
        "#     name='Get the User Needs Criteria',\n",
        "#     func=llm_chain.run,\n",
        "#     description= \"\"\"Use this tool when a user has expressed a need so that you can gather the following parameters [a: need] [b: location and zip code [c: times of the week] and[d: distance]\"\"\"\n",
        "# )\n",
        "\n",
        "# #tools.append(getUserNeeds)\n"
      ],
      "metadata": {
        "id": "zO9jqGvxLAsd"
      },
      "id": "zO9jqGvxLAsd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tool in tools:\n",
        "  print (tool.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4nLOi-eL1sM",
        "outputId": "1a8ce9a9-373e-461e-d3b9-74a4c723bcd5"
      },
      "id": "h4nLOi-eL1sM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program Recommendation\n",
            "Get User Needs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMYl6T4ZLIim",
        "outputId": "557ac2dd-6200-4c78-a8a7-90eaadf3dd38"
      },
      "id": "JMYl6T4ZLIim",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Tutorial with Open AI as LLM"
      ],
      "metadata": {
        "id": "0ZHljlzczAhO"
      },
      "id": "0ZHljlzczAhO"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall typing-extensions==4.7\n",
        "!pip install --force-reinstall openai==1.8"
      ],
      "metadata": {
        "id": "TC7xLoAludj4"
      },
      "id": "TC7xLoAludj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "4VKZFzdRwsS7"
      },
      "id": "4VKZFzdRwsS7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRnbHCteuLhv",
        "outputId": "a55e7d01-fd1a-45c0-8670-48137dcae8b4"
      },
      "id": "VRnbHCteuLhv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.8.0\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: llmx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying Out Open AI instead\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass()\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or 'OPENAI_API_KEY'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rnlUXF-xwIw8"
      },
      "id": "rnlUXF-xwIw8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize OpenAI ChatLLM\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "#Flush Memory buffer\n",
        "\n",
        "conversational_memory = ConversationBufferMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# initialize agent with tools\n",
        "agent_openAI = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=10,\n",
        "    early_stopping_method='generate',\n",
        "    memory=conversational_memory\n",
        ")\n",
        "\n",
        "from langchain.globals import set_debug\n",
        "from langchain.globals import set_verbose\n",
        "\n",
        "\n",
        "set_verbose(False)\n",
        "set_debug(False)\n"
      ],
      "metadata": {
        "id": "gWCtDZwlxojc"
      },
      "id": "gWCtDZwlxojc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print existing agent prompt\n",
        "print(agent_openAI.agent.llm_chain.prompt.messages[0].prompt.template)\n"
      ],
      "metadata": {
        "id": "tWZGQhC0z6bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b859b61-8080-41c3-d7b3-9d6fb7f3e90b"
      },
      "id": "tWZGQhC0z6bX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Message\n",
        "\n",
        "agent_openAI(\"I am looking for help finding food\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FDm6u6rCqLv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5a1c52a-f7df-42b3-c6ab-ebcbae3ff11a"
      },
      "id": "FDm6u6rCqLv3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Get the User Needs Criteria\",\n",
            "    \"action_input\": \"food\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "Your name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\n",
            "\n",
            "Given input from a user,  your goal is to gather the following required information and identify what is missing. \n",
            "\n",
            "The required information is the following 4 items:\n",
            "\n",
            "[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.  \n",
            "\n",
            "2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code.  It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\n",
            "\n",
            "3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\n",
            "\n",
            "4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”\n",
            "\n",
            "If the input is missing information, identify the missing information. \n",
            "\n",
            "If all 4 inputs are available, do not make up any information. Ask the for additiona details.\n",
            "\n",
            "If the input has all 4 criteria, output confirm the information with the user in the following format:\n",
            "\n",
            "“Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\n",
            "\n",
            "Is this correct?”\n",
            "\n",
            "Human: Hi. I am single mother of three children. I am looking for help finding some day care options for my three children after school. I live near Seattle and can only go at most 10 miles. The times I really need help are Weekends during the work week.\n",
            "AI: \n",
            "Based on your preferences, I can help you find daycare near Seattle WA, 98101 with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 10 miles. Is this correct?\n",
            "\n",
            "Human: I am really hungry and am currently staying in Austin. I can go 20 miles during the work week.\n",
            "AI: \n",
            "Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?\n",
            "\n",
            "Human: It's really cold right now and I am homeless staying near Berkeley. I am looking for warm clothing. I can walk maybe 5 miles during the day time.  \n",
            "AI: \n",
            "Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Monday through Friday 9-5. The maximum distance you want to travel is 5 miles. Is this correct?\n",
            "\n",
            "Human: I am hungry right now.\n",
            "AI: \n",
            "I can see that you might be looking for food shelter. So that I can help you, please provide the missing information:\n",
            "- Your Zip Code\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\n",
            "\n",
            "Human: I am being evicted from my apartment in Chicago. Can you help?\n",
            "AI: \n",
            "I can see that you might be looking for legal assistance in Chicago. So that I can help you, please provide the missing information:\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\n",
            "\n",
            "Human: food\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-116abaae8019>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Test Message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magent_openAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I am looking for help finding food\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1313\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1037\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1038\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1039\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1037\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1038\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1039\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                     \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                 observation = tool.run(\n\u001b[0m\u001b[1;32m   1135\u001b[0m                     \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             run_manager.on_tool_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_args_and_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             observation = (\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mnew_argument_supported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             return (\n\u001b[0;32m--> 510\u001b[0;31m                 self.func(\n\u001b[0m\u001b[1;32m    511\u001b[0m                     \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    480\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         flattened_outputs = [\n\u001b[1;32m    372\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 results.append(\n\u001b[0;32m--> 360\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    361\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m                 )\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                 return self._generate(\n\u001b[0m\u001b[1;32m    515\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chat_models/vertexai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mchat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmsg_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         generations = [\n\u001b[1;32m    189\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/language_models/_language_models.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, message, max_output_tokens, temperature, top_k, top_p, stop_sequences, candidate_count, grounding_source)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         )\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         prediction_response = self._model._endpoint.predict(\n\u001b[0m\u001b[1;32m   2194\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             )\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   1564\u001b[0m                 \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    605\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    942\u001b[0m                  \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                  compression=None):\n\u001b[0;32m--> 944\u001b[0;31m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[0m\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 ),), self._context)\n\u001b[0;32m--> 933\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_openAI(\"I am looking for a food shelter\")\n"
      ],
      "metadata": {
        "id": "A6w0753pTs-G"
      },
      "id": "A6w0753pTs-G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_openAI(\"I live in El Cerrito CA\")\n"
      ],
      "metadata": {
        "id": "k912C98P_zUt"
      },
      "id": "k912C98P_zUt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Change the Agent System Prompt\n",
        "\n",
        "# We have imported a new system message template from the upload files\n",
        "\n",
        "new_prompt = agent_openAI.agent.create_prompt(\n",
        "    system_message = system_template,\n",
        "    tools = tools\n",
        ")\n",
        "\n",
        "agent_openAI.agent.llm_chain.prompt = new_prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "5SbD5zioHXR_"
      },
      "id": "5SbD5zioHXR_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print existing agent prompt\n",
        "print(agent_openAI.agent.llm_chain.prompt.messages[0].prompt.template)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WUmkT-H3gt",
        "outputId": "3949a307-73e2-4186-ed1e-0d2fb2b8deb7"
      },
      "id": "s2WUmkT-H3gt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
            "\n",
            "Your goal is to gather the following required information denoted below  by numbers by asking a series of questions\n",
            "\n",
            "[1: Type of Service]. You can ask “What types of services are you looking for?” Acceptable answers include include “food shelters”, “homeless services”, “day care assistance” , “free closing”. It is typically a combination of keywords.\n",
            "\n",
            "2: [Location]: You can ask “What is the zip code where you want to get help?” or “What city would you like to get help”. Acceptable answers could be a City/State combination or a zip Code.  It is important to find a relevant zip code. If the request does not have a clear location, ask for the location where the person wants to receive help. If there are multiple cities in the United States with the same name, confirm the state the person lives. Using the information already requested with the new location information then generate the url with a term and zip code.\n",
            "\n",
            "3: [Distance]: You can ask “How far do you want to travel to get help?” Acceptable answers might include “I can travel 10 miles”\n",
            "\n",
            "4: [Day_times]: You can ask “What days and times during the week would you like to receive help?” Acceptable answers might include “I am only available on the weekends” or “The best times for me are monday through Friday before 5pm”\n",
            "\n",
            "When you have gathered all of the information output confirm the information with the user in the following format:\n",
            "\n",
            "“Based on your preferences, I can help you find [1: Type of Service] near [2:Location] with the most convenient times being [4: Day_times]. The maximum distance you want to travel is [3:Distance]\n",
            "\n",
            "Is this correct?”\n",
            "\n",
            "\n",
            "Example:\n",
            "\n",
            "“Based on your preferences, I can help you find food pantries near Austin TX with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 12 miles. Is this correct?”\n",
            "“Based on your preferences, I can help you find free clothing near Berkeley CA 94720 with the most convenient times being Wednesdays before 5pm. The maximum distance you want to travel is 5 miles. Is this correct?”\n",
            "“Based on your preferences, I can help you find after school care near Seattle with the most convenient times being Mondays through Friday from 8am to noon. The maximum distance you want to travel is 20 miles. Is this correct?”\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Message\n",
        "\n",
        "agent_openAI(\"I am looking for food\")"
      ],
      "metadata": {
        "id": "zoqxhwR4Io1C"
      },
      "id": "zoqxhwR4Io1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Vertex LLM powering Agent"
      ],
      "metadata": {
        "id": "GxfzTCRqzkAN"
      },
      "id": "GxfzTCRqzkAN"
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "#importlib.reload(AgentAuntBerthaPrompt)"
      ],
      "metadata": {
        "id": "IiOMFNDlKrWl"
      },
      "id": "IiOMFNDlKrWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize Vertex LLMs\n",
        "\n",
        "## For some reason the basic tutorial doesn't work with VertexChatLLM but it can work with the regular text model\n",
        "##chat_llm = ChatVertexAI()\n",
        "chat_VertexLLM = VertexAI(model_name=\"gemini-pro\")\n",
        "\n",
        "#vertex_llm = VertexAI(model_name = 'text-bison@001')\n"
      ],
      "metadata": {
        "id": "kL3cRb94q5v5"
      },
      "id": "kL3cRb94q5v5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Long-Term Memory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "JejM-Edkbyqp"
      },
      "id": "JejM-Edkbyqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different LLM in Agent Framework\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "\n",
        "#Flush Memory buffer\n",
        "\n",
        "conversational_memory = ConversationBufferMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# initialize the agent\n",
        "agent_Vertex = initialize_agent(\n",
        "    agent='conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=chat_VertexLLM,\n",
        "    verbose=False,\n",
        "    max_iterations=3,\n",
        "    memory=conversational_memory,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8E-XSCd7-1En"
      },
      "id": "8E-XSCd7-1En",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_verbose\n",
        "\n",
        "set_verbose(False)"
      ],
      "metadata": {
        "id": "55XM0xiKIQ-m"
      },
      "id": "55XM0xiKIQ-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Chat Loop\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter your input (type 'exit' to stop): \")\n",
        "\n",
        "    # Check if the user wants to exit the loop\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    #Get the first response\n",
        "    response = agent_Vertex.invoke(user_input)\n",
        "    print(f\"System Response: {response['chat_history'][-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM9zjHZXEVEQ",
        "outputId": "ae64e414-427b-46ed-bba2-dd6aaab1799e"
      },
      "id": "tM9zjHZXEVEQ",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your input (type 'exit' to stop): I am looking for help finding a food pantry near El Cerrito CA\n",
            "System Response: content=\"I see you're looking for a food pantry near El Cerrito, CA. Is there anything else I can help you with?\"\n",
            "Enter your input (type 'exit' to stop): No\n",
            "System Response: content=\"Okay. To find a food pantry near El Cerrito, CA, I'll just need a little more information from you. Could you tell me what days of the week work best for you to visit a food pantry, and how far are you willing to travel?\"\n",
            "Enter your input (type 'exit' to stop): Friday afternoons\n",
            "System Response: content='Okay, how far are you willing to travel to a food pantry on Friday afternoons?'\n",
            "Enter your input (type 'exit' to stop): 10 miles\n",
            "System Response: content='Okay, I’ll search for food pantries near El Cerrito, CA, 94530 that are open on Friday afternoons within a 10-mile radius. Does this sound right?'\n",
            "Enter your input (type 'exit' to stop): Yes\n",
            "System Response: content='Yes, that information is correct. I’ll go ahead and search for food pantries near El Cerrito, CA, 94530 that are open on Friday afternoons within a 10-mile radius. Please let me know if you have any questions while we search.'\n",
            "Enter your input (type 'exit' to stop): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Message\n",
        "\n",
        "current_outcome = agent_Vertex(\"I am looking for help finding a food pantry near El Cerrito CA \")"
      ],
      "metadata": {
        "id": "IPG0XpRW_Asm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aef3098-101e-46e4-baec-aaf42070f212"
      },
      "id": "IPG0XpRW_Asm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: null\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI can see that you might be looking for assistance. So that I can help you, please provide the missing information:\n",
            "- Type of service you need\n",
            "- Your Zip Code\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Hi there, I'm here to help you find a food pantry near El Cerrito, CA. To get started, can you please provide me with the following information:\n",
            "- Your Zip Code\n",
            "- How far are you willing to travel for food assistance?\n",
            "- What are the most convenient days and times of the week for you to visit a food pantry?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (current_outcome['chat_history'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zzCtMFDLvHZ",
        "outputId": "00b48259-8512-49fa-b73e-383465b2179d"
      },
      "id": "_zzCtMFDLvHZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Hi there, I'm here to help you find a food pantry near El Cerrito, CA. To get started, can you please provide me with the following information:\\n- Your Zip Code\\n- How far are you willing to travel for food assistance?\\n- What are the most convenient days and times of the week for you to visit a food pantry?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_outcome = agent_Vertex(\"I can go 10 miles on the weekend\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNkarvmI6o8d",
        "outputId": "aef0611d-efc0-4d11-ffc5-4140354981d2"
      },
      "id": "UNkarvmI6o8d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: I can go 10 miles on the weekend\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI can see that you might be looking for free closing assistance. So that I can help you, please provide the missing information:\n",
            "- City and State or Zip Code\n",
            "- Type of service you are looking for\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Got it, so you're looking for a food pantry in the El Cerrito area, CA within a 10-mile radius on the weekends. Would you like me to suggest some options?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (current_outcome['chat_history'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_sUgF6g6zYO",
        "outputId": "823f8c76-60df-43f2-9f4c-31b0df9ef61d"
      },
      "id": "n_sUgF6g6zYO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Got it, so you're looking for a food pantry in the El Cerrito area, CA within a 10-mile radius on the weekends. Would you like me to suggest some options?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_outcome = agent_Vertex(\"Yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcAZCeVm7H_m",
        "outputId": "4cc9dd8f-0fe9-4826-e399-ef5ee10341eb"
      },
      "id": "kcAZCeVm7H_m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: None\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI can see that the information you have provided is insufficient. So that I can help you, please provide the following missing information:\n",
            "- What type of services are you looking for\n",
            "- Your Zip Code\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Thank you for providing that information. I understand that you are looking for a food pantry within a 10-mile radius of El Cerrito, CA, and you can visit on the weekends. Can you please provide me with your zip code so I can narrow down the search results?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_outcome = agent_Vertex(\"94530\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHSJNVmf7UXe",
        "outputId": "dff29129-4928-4ac8-fd3a-df9c3c3bd1a5"
      },
      "id": "pHSJNVmf7UXe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: - Zip: 94530, - Distance 10, - Weekends\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mBased on your preferences, I can help you find services near Campbell CA, 95008 with the most convenient times being Saturday and Sunday during the day. The maximum distance you want to travel is 10 miles. Is this correct?\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Great! I've got a few food pantries that meet your criteria in Campbell CA, 95008. They're all open on the weekends during the day and within 10 miles of your location. Would you like me to list them for you?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Try to get this in the new REACT supported langchain function calls\n",
        "####https://python.langchain.com/docs/modules/agents/agent_types/react"
      ],
      "metadata": {
        "id": "r4PJs8PZ7oIt"
      },
      "id": "r4PJs8PZ7oIt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub"
      ],
      "metadata": {
        "id": "205_WrQ2W1Qc"
      },
      "id": "205_WrQ2W1Qc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent"
      ],
      "metadata": {
        "id": "LhskZ2rG7y2I"
      },
      "id": "LhskZ2rG7y2I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react-chat\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UM_J8W_171Pz"
      },
      "id": "UM_J8W_171Pz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aunt_bertha_agent = \"\"\"\n",
        "Assistant is a large language model and your name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service.\n",
        "Your task is to assist humans Find non-profit programs to create referrals.\n",
        "\n",
        "Aunt Bertha is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "\n",
        "TOOLS:\n",
        "------\n",
        "\n",
        "Assistant has access to the following tools:\n",
        "{tools}\n",
        "\n",
        "If you do not have information to pass to a tool, omit the value.\n",
        "\n",
        "To use a tool, please use the following format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? Yes\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "```\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? No\n",
        "Final Answer: [your response here]\n",
        "```\n",
        "\n",
        "Begin!\n",
        "\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "\n",
        "New input: {input}\n",
        "{agent_scratchpad}\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VYVEjPNFAF2W"
      },
      "id": "VYVEjPNFAF2W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ2DZEtg-H1S",
        "outputId": "00027bb2-4a56-4721-c776-043eefbcc239"
      },
      "id": "xQ2DZEtg-H1S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n{tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.template = aunt_bertha_agent"
      ],
      "metadata": {
        "id": "y3NVEIWMA86n"
      },
      "id": "y3NVEIWMA86n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the ReAct agent\n",
        "agent = create_react_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "CwXek12G73zL"
      },
      "id": "CwXek12G73zL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flush Memory buffer\n",
        "\n",
        "conversational_memory2 = ConversationBufferMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "3NXltypy9bYy"
      },
      "id": "3NXltypy9bYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=False, handle_parsing_errors=True, memory=conversational_memory2\n",
        ")"
      ],
      "metadata": {
        "id": "2qHwqKI48XAw"
      },
      "id": "2qHwqKI48XAw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Chat Loop\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter your input (type 'exit' to stop): \")\n",
        "\n",
        "    # Check if the user wants to exit the loop\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    #Get the first response\n",
        "    response = agent_executor.invoke({\"input\": user_input})\n",
        "    print(f\"System Response: {response['chat_history'][-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__EWS1CsCGe4",
        "outputId": "4c794181-6484-4cb1-8341-6f06a44272a5"
      },
      "id": "__EWS1CsCGe4",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your input (type 'exit' to stop): I am looking for a food pantry near zip code 94530\n",
            "System Response: content='There is a St. Vincent de Paul Society Food Pantry run by the St. Jerome Catholic Church that is located at 308 Carmel Avenue, El Cerrito, CA 94530 that is open on Wednesdays from 10:30am to 11:30am PST.'\n",
            "Enter your input (type 'exit' to stop): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer = agent_executor.invoke({\"input\": \"I am looking for help finding a food pantry near El Cerrito CA\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf44bpmb9gsJ",
        "outputId": "3fff79a7-37c4-4aec-dfe3-29a65a5d60d5"
      },
      "id": "Lf44bpmb9gsJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: {}\u001b[0m\u001b[36;1m\u001b[1;3mI can see that you might be looking for social services. So that I can help you, please provide the missing information:\n",
            "- Types of services you are looking for\n",
            "- Your Zip Code or city\n",
            "- How far are you willing to travel\n",
            "- What are the most convenient days and times of the week\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "Final Answer: Hi there, I am happy to help you find the nearest food pantry in El Cerrito, CA. Can you please clarify whether you are looking for a food bank, soup kitchen, or another type of food assistance program? Additionally, can you please provide your zip code so that I can search for nearby resources?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (llm_answer['chat_history'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgRMRJny_QdX",
        "outputId": "74c86354-17dd-428c-92c2-1c9df77e8c8b"
      },
      "id": "rgRMRJny_QdX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hi there, I am happy to help you find the nearest food pantry in El Cerrito, CA. Can you please clarify whether you are looking for a food bank, soup kitchen, or another type of food assistance program? Additionally, can you please provide your zip code so that I can search for nearby resources?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer = agent_executor.invoke({\"input\": \"I can visit on weekends\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DPySM8a_YgJ",
        "outputId": "5e8e6f34-4981-4774-efa8-5e5532d0d94c"
      },
      "id": "3DPySM8a_YgJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Get User Needs\n",
            "Action Input: {need: food pantry, location: El Cerrito, CA, times: weekends, distance: not specified}\u001b[0m\u001b[36;1m\u001b[1;3mBased on your preferences, I can help you find food pantries near El Cerrito, 94533 with the most convenient times being Saturday and Sunday during the day.  Is this correct?\u001b[0m\u001b[32;1m\u001b[1;3m```\n",
            "Do I need to use a tool? No\n",
            "Final Answer: Based on your preferences, I can help you find food pantries near El Cerrito, 94533 with the most convenient times being Saturday and Sunday during the day. Is this correct? Once you confirm, I'll compile a list of nearby food pantries that align with your requirements.\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (llm_answer['chat_history'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHoA8TC5_fs_",
        "outputId": "ea9a3983-5011-4214-c551-9a9e15cbb19b"
      },
      "id": "rHoA8TC5_fs_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Based on your preferences, I can help you find food pantries near El Cerrito, 94533 with the most convenient times being Saturday and Sunday during the day. Is this correct? Once you confirm, I'll compile a list of nearby food pantries that align with your requirements.\\n```\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_Vertex.agent.llm_chain.prompt)"
      ],
      "metadata": {
        "id": "BxshtmrTBdoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434dc81d-3599-4bbb-ba43-91b747191018"
      },
      "id": "BxshtmrTBdoc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['agent_scratchpad', 'chat_history', 'input'] template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n> Get the User Needs Criteria: Use this tool when a user has expressed a need so that you can gather the following parameters [a: need] [b: location and zip code [c: times of the week] and[d: distance]\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [Get the User Needs Criteria]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}'\n"
          ]
        }
      ]
    }
  ]
}