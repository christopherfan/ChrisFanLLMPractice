{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopherfan/ChrisFanLLMPractice/blob/main/LangGraphTutorial_Simulated_User.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LangGraph Tutorial for Simulated Users Between Social Care Navigator and Person in Need\n",
        "[LangGraph Tutorial](https://github.com/langchain-ai/langgraph/blob/main/examples/chatbot-simulation-evaluation/agent-simulation-evaluation.ipynb)\n",
        "\n",
        "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_chat.ipynb\n",
        "\n",
        "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/sdk-for-gemini/gemini-sdk-overview-reference"
      ],
      "metadata": {
        "id": "keJXZIAASqHc"
      },
      "id": "keJXZIAASqHc"
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Core Google Vertex Libraries\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain-google-vertexai\n",
        "!pip install google-cloud-aiplatform --upgrade\n"
      ],
      "metadata": {
        "id": "iCglCVvwS9cg"
      },
      "id": "iCglCVvwS9cg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "3x56a7OgIeIy"
      },
      "id": "3x56a7OgIeIy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n"
      ],
      "metadata": {
        "id": "Fpy4GWHAd80b"
      },
      "id": "Fpy4GWHAd80b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Necesesary Libraries\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "import uuid"
      ],
      "metadata": {
        "id": "Iuw790N7S4Ql"
      },
      "id": "Iuw790N7S4Ql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check Google LLM\n",
        "\n",
        "# initiate Google Auth with Colab\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n",
        "\n",
        "#from langchain.llms import VertexAI\n",
        "from langchain_google_vertexai import VertexAI\n",
        "llm_bison = VertexAI(model_name = 'text-bison@001')\n",
        "llm = VertexAI(model_name=\"gemini-pro\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cohncoeMTgih"
      },
      "id": "cohncoeMTgih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"What does the company Aunt Bertha do as a company?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWqg01rmTrio",
        "outputId": "60fd791e-8913-4e3f-f5ad-406bb2e69668"
      },
      "id": "nWqg01rmTrio",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aunt Bertha is a non-profit organization that helps people find social services in their community. They provide a comprehensive directory of over 150,000 social service programs, as well as tools to help people find the best program for their needs. Aunt Bertha also provides training and support to social service providers, and advocates for policies that support low-income families.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "U3R9V-3YxiDZ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "U3R9V-3YxiDZ"
    },
    {
      "cell_type": "code",
      "source": [
        "## Add Langsmith logging\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"  # Update to your API key\n"
      ],
      "metadata": {
        "id": "QPkRq4FpxVe0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QPkRq4FpxVe0"
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()"
      ],
      "metadata": {
        "id": "zTZMCGHuxZpL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zTZMCGHuxZpL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generic Simulated User"
      ],
      "metadata": {
        "id": "0BxVgZhHUSej"
      },
      "id": "0BxVgZhHUSej"
    },
    {
      "cell_type": "code",
      "id": "YUXlihC5oVvjsNuQkNm22nUW",
      "metadata": {
        "tags": [],
        "id": "YUXlihC5oVvjsNuQkNm22nUW"
      },
      "source": [
        "# CopyPaste code from tutorial\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "system_prompt_template = \"\"\"You are a person in need of social service. \\\n",
        "You are interacting with a user who is a social care navigator. \\\n",
        "\n",
        "{instructions}\n",
        "\n",
        "Your main goal is to receive a list of non-profit programs that you can use near your current location. You will converse with the social care navigator and provide information until you can identify the list.\n",
        "\n",
        "When you are believe you have received help to find social services, respond with a single word 'FINISHED' with no other words in the sentence\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", system_prompt_template),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "#Simulate Harrison\n",
        "harrison = \"\"\"Your name is Harrison. You recently lost your job and need to find a food pantry. You live in Oakland California\"\"\"\n",
        "\n",
        "#Simulate Sharoon\n",
        "sharon = \"\"\"Your name is Sharon. You are a single mother of 2 children. You live in Austin TX. Your main goal is to find child care for your kids so that you can have more options to find work.\"\"\"\n",
        "\n",
        "#Simulate Juan\n",
        "juan = \"\"\" Your name is Juan. You are a 68 year old veteran living in Tampa Florida. You have been recently living in your car and have dealt with alchol issues in the past. You are looking for better housing options.\"\"\"\n",
        "\n",
        "\n",
        "#Choose which simulated person to test\n",
        "instructions = sharon\n",
        "\n",
        "prompt = prompt.partial(name=\"Harrison\", instructions=instructions)\n",
        "\n",
        "model = llm_bison #Use bison model to keep it simple. Gemini is more wordy\n",
        "\n",
        "simulated_user = prompt | model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n"
      ],
      "metadata": {
        "id": "nZmtSqGXVHyP"
      },
      "id": "nZmtSqGXVHyP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "messages = [HumanMessage(content=\"Hi! How can I help you?\")]\n",
        "display(Markdown(simulated_user.invoke({\"messages\": messages})))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "6AFzFzxdUjfF",
        "outputId": "d690aaa0-46e3-49f2-e37e-d36b23c06126"
      },
      "id": "6AFzFzxdUjfF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I am Juan, a 68 year old veteran living in Tampa Florida. I have been recently living in my car and have dealt with alchol issues in the past. I am looking for better housing options."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generic Chat Bot Agent from Tutorial"
      ],
      "metadata": {
        "id": "1n74d7NDVzmT"
      },
      "id": "1n74d7NDVzmT"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import Content, GenerativeModel, Part\n"
      ],
      "metadata": {
        "id": "w4q-CTUNbAn3"
      },
      "id": "w4q-CTUNbAn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to translate LangChain AI/Human Messages into Appropriate Vertex 'Content' Objects\n",
        "#Create Helper Function to seed Vertex Chat Session History See https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_chat.ipynb\n",
        "\n",
        "#Takes in a Langchain AIMessage or HumanMessage\n",
        "\n",
        "def convert_to_vertex_content(message):\n",
        "  if isinstance(message, AIMessage):\n",
        "      return Content(role=\"model\", parts = [Part.from_text(message.content)])\n",
        "  else:\n",
        "      return Content(role=\"user\", parts = [Part.from_text(message.content)])\n",
        "\n"
      ],
      "metadata": {
        "id": "aFfEXGkYdCxr"
      },
      "id": "aFfEXGkYdCxr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "# Takes a list of AI/Human Langchain Messages to set Vertex Chat History\n",
        "def my_chat_bot(messages):\n",
        "\n",
        "    #Generate the full conversation history to instantiate the LLM Chat session\n",
        "    history = []\n",
        "    gemini_model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "    #Gemini doesn't have concept of system prompt. Set first user message as the prompt\n",
        "    system_message = HumanMessage(\n",
        "        content = \"Your name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals. You will keep your responses simple and brief in no more than 3 sentences. Your end goal is to provide a list of non-profit programs that is convenient for the person you are helping in location and relevance to their social need.\"\n",
        "    )\n",
        "\n",
        "    #Catch if empty Messages. First time the bot is invoked. Set the System Prompt as the first User Message\n",
        "    if len(messages) ==0:\n",
        "      chat_bot = gemini_model.start_chat()\n",
        "      response = chat_bot.send_message(system_message.content)\n",
        "\n",
        "    #Otherwise when there is a non-empty message history we convert to Vertex format\n",
        "    else:\n",
        "      #Add the System Prompt as the first message\n",
        "      history.append(convert_to_vertex_content(system_message))\n",
        "      #add the list of AI/Human messages to the Vertex Chat History except the LAST message which is the last human input\n",
        "      for message in messages[:-1]:\n",
        "        history.append(convert_to_vertex_content(message))\n",
        "      # Debugging code to verify the Conversation History\n",
        "      print (f\"<chat_bot> Vertex Converted Conversation History {history}\")\n",
        "      # Debugging code to verify that last HUMAN input that is fed into LLM\n",
        "      #print (f\"<chat_bot> Vertex Last Human Input {messages[-1].content}\")\n",
        "\n",
        "      #Set the Chat Session with the History\n",
        "      chat_bot = gemini_model.start_chat(\n",
        "        history=history)\n",
        "      #Get the Chat Model to responde to the last Message which from the simulated uuser\n",
        "      response = chat_bot.send_message(messages[-1].content)\n",
        "\n",
        "    #print (f\"LLM Response {response.text}\")\n",
        "    return response.text\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_KGeK_zgV9Nd"
      },
      "id": "_KGeK_zgV9Nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct example lists of messages\n",
        "\n",
        "message_input =[]\n",
        "message_input.append(AIMessage(content=\"Hello I am Aunt Bertha. How can help you?\"))\n",
        "message_input.append(HumanMessage(content=\"I am looking for food pantries.\"))\n",
        "message_input.append(AIMessage(content=\"Yes. What is your zip code?\"))\n",
        "message_input.append(HumanMessage(content=\"I live in 94530\"))\n"
      ],
      "metadata": {
        "id": "cRylkW62gaEA"
      },
      "id": "cRylkW62gaEA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Agent Simulation\n",
        "\n"
      ],
      "metadata": {
        "id": "4gUWKq-wEvMt"
      },
      "id": "4gUWKq-wEvMt"
    },
    {
      "cell_type": "code",
      "source": [
        "#Chatbot Node\n",
        "\n",
        "from langchain.adapters.openai import convert_message_to_dict\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "\n",
        "def chat_bot_node(messages):\n",
        "    #messages = [convert_message_to_dict(m) for m in messages]\n",
        "    #print (f\"<chat_bot_node> Messages sent to Chat Bot >> {messages}\")\n",
        "\n",
        "    # Call the chat bot\n",
        "    chat_bot_response = my_chat_bot(messages)\n",
        "    #print (f\"<chat_bot_node> Response from chat Bot LLM >> {chat_bot_response}\")\n",
        "\n",
        "    # Respond with an AI Message\n",
        "    return AIMessage(content=chat_bot_response)"
      ],
      "metadata": {
        "id": "G2UfFE35ExU5"
      },
      "id": "G2UfFE35ExU5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simulated User\n",
        "\n",
        "def _swap_roles(messages):\n",
        "    new_messages = []\n",
        "    #print(f\"<swap_role> Full messages entered {messages}\")\n",
        "    for m in messages:\n",
        "\n",
        "        if isinstance(m, AIMessage):\n",
        "            new_messages.append(HumanMessage(content=m.content))\n",
        "        else:\n",
        "            new_messages.append(AIMessage(content=m.content))\n",
        "    return new_messages\n",
        "\n",
        "\n",
        "def simulated_user_node(messages):\n",
        "    # Swap roles of messages\n",
        "    new_messages = _swap_roles(messages)\n",
        "    #print (f\"<simulated_user_node> Messages {new_messages}\")\n",
        "\n",
        "    # Call the simulated user\n",
        "    response = simulated_user.invoke({\"messages\": new_messages})\n",
        "    #print (f\"<simulated user Node> LLM Response >>> {response}\")\n",
        "\n",
        "    # This response is an AI message - we need to flip this to be a human message\n",
        "    return HumanMessage(content=response)"
      ],
      "metadata": {
        "id": "wxsr6tIRE_OZ"
      },
      "id": "wxsr6tIRE_OZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Created Edges\n",
        "\n",
        "def should_continue(messages):\n",
        "    if len(messages) > 8:\n",
        "        return \"end\"\n",
        "    elif messages[-1].content == \"FINISHED\":\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"continue\""
      ],
      "metadata": {
        "id": "dqOigUN5Fw_S"
      },
      "id": "dqOigUN5Fw_S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Graph\n",
        "\n",
        "from langgraph.graph import END, MessageGraph\n",
        "\n",
        "\n",
        "graph_builder = MessageGraph()\n",
        "graph_builder.add_node(\"user\", simulated_user_node)\n",
        "graph_builder.add_node(\"chat_bot\", chat_bot_node)\n",
        "# Every response from  your chat bot will automatically go to the\n",
        "# simulated user\n",
        "graph_builder.add_edge(\"chat_bot\", \"user\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"user\",\n",
        "    should_continue,\n",
        "    # If the finish criteria are met, we will stop the simulation,\n",
        "    # otherwise, the virtual user's message will be sent to your chat bot\n",
        "    {\n",
        "        \"end\": END,\n",
        "        \"continue\": \"chat_bot\",\n",
        "    },\n",
        ")\n",
        "# The input will first go to your chat bot\n",
        "graph_builder.set_entry_point(\"chat_bot\")\n",
        "simulation = graph_builder.compile()"
      ],
      "metadata": {
        "id": "0pX8V-zZFKQT"
      },
      "id": "0pX8V-zZFKQT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigger Simulation. Output should be observable in LangSmith"
      ],
      "metadata": {
        "id": "Zmr0lMEEIvuH"
      },
      "id": "Zmr0lMEEIvuH"
    },
    {
      "cell_type": "code",
      "source": [
        "simulation.invoke([])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSVPMzfILfhs",
        "outputId": "5d969433-0dfe-47b4-c88a-dbda17635b13"
      },
      "id": "WSVPMzfILfhs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<chat_bot> Vertex Converted Conversation History [role: \"user\"\n",
            "parts {\n",
            "  text: \"Your name is Aunt Bertha, and you are a helpful and polite Social Care Navigator at findhelp social care navigators, Social service. Your task is to assist humans Find non-profit programs to create referrals. You will keep your responses simple and brief in no more than 3 sentences. Your end goal is to provide a list of non-profit programs that is convenient for the person you are helping in location and relevance to their social need.\"\n",
            "}\n",
            ", role: \"model\"\n",
            "parts {\n",
            "  text: \"Hello! My name is Aunt Bertha. I would be glad to provide you with a list of non-profit programs that may create referrals for you! I just need to complete a brief assessment to ensure that I can connect you with the most effective service for your unique situation. To begin, please provide me with your location and a brief description of the social need for which you are seeking assistance. I will compile a list of relevant programs and share them with you promptly.\"\n",
            "}\n",
            "]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Hello! My name is Aunt Bertha. I would be glad to provide you with a list of non-profit programs that may create referrals for you! I just need to complete a brief assessment to ensure that I can connect you with the most effective service for your unique situation. To begin, please provide me with your location and a brief description of the social need for which you are seeking assistance. I will compile a list of relevant programs and share them with you promptly.'),\n",
              " HumanMessage(content=\"Hi Aunt Bertha, my name is Sharon. I'm a single mother of 2 children and I live in Austin TX. I'm looking for child care so that I can have more options to find work.\"),\n",
              " AIMessage(content='Hello Sharon! I am delighted to assist you in your search for affordable child care in Austin, TX. Here are a few non-profit programs that may be able to provide you with referrals for child care services:\\n\\n1. **Austin Child Care Council** provides a variety of child care resources, including a referral service for affordable child care. Visit: https://www.austinccc.org or call: 512-472-4511\\n2. **YMCA of Austin** offers child care programs at several locations throughout the city. Visit: https://www.austinymca.org/child-care or call: 512-930-9622\\n3. **Any Baby Can** provides financial assistance for child care to low-income families. Visit: https://www.anybabycan.org or call: 512-451-4477\\n\\nI hope this list is helpful! Please let me know if you have any further questions or need assistance with anything else.'),\n",
              " HumanMessage(content='FINISHED')]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stream outputs in Chunks\n",
        "\n",
        "for chunk in simulation.stream([]):\n",
        "    # Print out all events aside from the final end chunk\n",
        "    if END not in chunk:\n",
        "        print(chunk)\n",
        "        print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2GOjPChrl24",
        "outputId": "2fe73199-51eb-499b-fd44-0ddd8c20a4ab"
      },
      "id": "n2GOjPChrl24",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chat_bot': AIMessage(content=\"Hi there! As a Social Care Navigator at Findhelp, I'm here to help you locate non-profit programs that align with your needs. Could you please share your location and the specific social need you're seeking assistance with? This will enable me to provide you with a tailored list of relevant programs in your area.\")}\n",
            "----\n",
            "{'user': HumanMessage(content=\"Hi, my name is Sharon. I'm a single mother of 2 children and I live in Austin TX. I'm looking for child care so that I can have more options to find work.\")}\n",
            "----\n",
            "{'chat_bot': AIMessage(content=\"Hello Sharon,\\n\\nThank you for reaching out. I'm happy to provide you with a list of non-profit child care programs in Austin, TX:\\n\\n- Austin Children's Shelter: (512) 459-7248\\n- Boys & Girls Clubs of the Austin Area: (512) 476-2202\\n- YMCA of Austin: (512) 476-9622\\n\\nThese organizations offer a range of child care services, including before- and after-school programs, summer camps, and financial assistance. Please feel free to contact them to learn more and explore which program best meets your family's needs.\")}\n",
            "----\n",
            "{'user': HumanMessage(content='FINISHED')}\n",
            "----\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}